# -*- coding: utf-8 -*-
"""Sprint1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_AXl4Vg8VBZPOu3YGUXdsXFxjDbhu5gT
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn as sk55748
import seaborn as sns
import missingno as msn
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier

df=pd.read_csv('/content/IndianWeatherRepository.csv')

df.shape

df.head()

df.describe()

df.info()

df.dtypes

df.isnull().sum()

df.columns

df.corr()

plt.figure(figsize=(15,8));
plt.title("Correlation",color="green")
sns.heatmap(df.corr(),linewidth=1,annot=True);

df.duplicated().value_counts()

df.drop_duplicates()

fig,ax=plt.subplots(ncols=3,nrows=2,figsize=(20,10))
hg=df[['temperature_celsius','wind_kph','pressure_mb','humidity','cloud']]
index=0
ax=ax.flatten()
for col,value in hg.items():
  sns.boxplot(y=col,data=hg,ax=ax[index])
  index +=1
plt.tight_layout(pad=0.5,w_pad=0.7,h_pad=5.0)

def get_outliers(df, col):
  q1 = df[col].quantile(0.25)
  q3 = df[col].quantile(0.75)
  iqr = q3 - q1
  fence_low = q1 - (1.5 * iqr)
  fence_high = q3 + (1.5 * iqr)
  outliers = df[col][(df[col] < fence_low) | (df[col] > fence_high)]
  return outliers

df_new = df.copy()
for col in df.columns:
  if not np.issubdtype(df_new[col], np.number):
    df_new[col] = pd.to_numeric(df_new[col], errors='coerce')

  outliers = get_outliers(df_new, col)
  df_new = df_new.drop(outliers.index)

fig,ax=plt.subplots(ncols=3,nrows=2,figsize=(20,10))
hg=df_new[['temperature_celsius','wind_kph','pressure_mb','humidity','cloud']]
index=0
ax=ax.flatten()
for col,value in hg.items():
  sns.boxplot(y=col,data=hg,ax=ax[index])
  index +=1
plt.tight_layout(pad=0.5,w_pad=0.7,h_pad=5.0)

X = df.drop(columns= 'condition_text')
y = df['condition_text']

y.value_counts()

import pandas as pd

# Load your dataset into a pandas DataFrame (replace 'data.csv' with your actual data file)
# df = pd.read_csv('your_dataset.csv')

# List of classes to be removed
classes_to_remove = [
    "Moderate or heavy rain with thunder",
    "Patchy light drizzle",
    "Patchy light rain",
    "Patchy light rain with thunder",
    "Moderate rain at times",
    "Heavy rain",
    "Thundery outbreaks possible",
    "Torrential rain shower",
    "Light freezing rain",
    "Light snow showers",
    "Heavy rain at times",
    "Patchy snow possible",
    "Patchy light snow with thunder",
    "Light sleet",
    "Moderate or heavy snow showers",
    "Clear"
]

# Remove rows associated with the specified classes
filtered_df = df[~df['condition_text'].isin(classes_to_remove)]

# Now, 'filtered_df' contains your dataset with the specified classes removed

filtered_df.info()

filtered_df.shape

X = filtered_df.drop(columns= 'condition_text')
y = filtered_df['condition_text']

y.value_counts()

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Assuming 'target_variable' is the column name for the target variable
# X = filtered_df.drop(['condition_text','region','location_name'], axis=1)  # Features
X = filtered_df.drop(['condition_text'], axis=1)  # Features
y = filtered_df['condition_text']  # Target variable

# Handle categorical variables using one-hot encoding
X = pd.get_dummies(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Instantiate the SMOTE object
smote = SMOTE(random_state=42)

# Fit and transform the training data
X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)

import matplotlib.pyplot as plt

# Count the occurrences of each class before oversampling
class_counts_before = y.value_counts()

# Count the occurrences of each class after oversampling
y_train_oversampled_counts = pd.Series(y_train_oversampled).value_counts()

# Plotting the bar graph
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
class_counts_before.plot(kind='bar', color='skyblue')
plt.title('Class Distribution (Before Balancing)')
plt.xlabel('Class')
plt.ylabel('Count')

plt.subplot(1, 2, 2)
y_train_oversampled_counts.plot(kind='bar', color='lightgreen')
plt.title('Class Distribution (After Balancing)')
plt.xlabel('Class')
plt.ylabel('Count')

plt.tight_layout()
plt.show()

from sklearn.preprocessing import LabelEncoder
label_Encoder=LabelEncoder()
filtered_df['condition_text']=label_Encoder.fit_transform(filtered_df['condition_text'])
# filtered_df['location_name']=label_Encoder.fit_transform(filtered_df['location_name'])
# filtered_df['region']=label_Encoder.fit_transform(filtered_df['region'])
label_Encoder.classes_

encoder1=LabelEncoder()
encoder2=LabelEncoder()
filtered_df['location_name']=encoder1.fit_transform(filtered_df['location_name'])
filtered_df['region']=encoder2.fit_transform(filtered_df['region'])

encoder1.classes_

encoder2.classes_

label_Encoder.classes_

filtered_df.head()

filtered_df.condition_text.value_counts()

x=filtered_df.drop(['condition_text'],axis=1)
x

y=filtered_df['condition_text']
y